# Pipeline Investigation Kit

**A lightweight, open-source toolkit for investigating data pipeline failures.**

Pipeline Investigation Kit helps teams **observe, diagnose, and replay data issues** such as:

* late or out-of-order events
* missing days or windows
* duplicate ingestion
* inconsistent aggregates
* unexplained metric changes

It is **not** a production data pipeline.
It is a **truth-preserving investigation layer** you can deploy in under an hour.

---

## Why This Exists

Modern data pipelines fail silently.

By the time a dashboard is wrong:

* raw data is gone
* retries are invisible
* aggregates have overwritten history

This project solves that by introducing **immutable capture + controlled replay**.

---

## What This Toolkit Is

* âœ” Immutable raw event storage
* âœ” Idempotent ingestion
* âœ” Fine-grained replay by entity & time window
* âœ” Safe, opt-in processing
* âœ” Full observability (logs + metrics)
* âœ” Designed for debugging, not throughput

---

## What This Toolkit Is NOT

* âœ˜ Not a streaming platform
* âœ˜ Not a full ETL system
* âœ˜ Not a replacement for your data warehouse
* âœ˜ Not a real-time analytics engine

It complements your pipeline â€” it does not replace it.

---

## High-Level Architecture

**Ingest â†’ Store â†’ Inspect â†’ Replay â†’ (Optionally) Process**:

* Events are ingested once
* Raw data is stored immutably in S3
* Metadata is indexed in DynamoDB
* Replay selectively re-emits events
* Processor computes versioned aggregates (optional)

Every step is independently observable and reversible.

---

## Typical Use Cases

* Debugging missing daily aggregates
* Investigating delayed syncs
* Replaying historical data safely
* Auditing aggregate changes
* Understanding duplicate storms

---

## Design Principles

* **Investigation first**
* **Immutability over mutation**
* **Observability over automation**
* **Safety over convenience**
* **Reversible by default**

If something looks â€œinefficientâ€, it is probably intentional.

---

## Quick Start

Deploy with processor disabled:

```bash
sam deploy --guided
```

Start ingesting events immediately.

Enable replay and processor only when needed.

ğŸ‘‰ See **Quickstart** for a hands-on walkthrough.

---

## Documentation Structure

* **Quickstart** â†’ get running fast
* **Architecture** â†’ understand how it works
* **Guide** â†’ operate and debug safely
* **Services** â†’ API & component details
* **FAQ** â†’ common questions and pitfalls

---

## Who This Is For

* Backend engineers
* Data engineers
* Platform teams
* On-call responders
* Anyone debugging â€œimpossibleâ€ data bugs

If youâ€™ve ever said *â€œthe data just disappearedâ€*, this is for you.

---

## Open Source

* MIT License
* Easy to fork
* Minimal AWS footprint
* Designed to be extended

Contributions are welcome.

ğŸ‘‰ See [CONTRIBUTING.md](contrib.md)

---

## Next Steps

* ğŸ“˜ Read the **Quickstart**
* ğŸ§  Explore the **Architecture**
* ğŸ›  Deploy in a dev environment
* ğŸ” Use it during your next incident

---

**Pipeline Investigation Kit**
*Observe first. Replay safely. Understand the truth.*
