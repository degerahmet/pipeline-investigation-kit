{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Pipeline Investigation Kit","text":"<p>A lightweight, open-source toolkit for investigating data pipeline failures.</p> <p>Pipeline Investigation Kit helps teams observe, diagnose, and replay data issues such as:</p> <ul> <li>late or out-of-order events</li> <li>missing days or windows</li> <li>duplicate ingestion</li> <li>inconsistent aggregates</li> <li>unexplained metric changes</li> </ul> <p>It is not a production data pipeline. It is a truth-preserving investigation layer you can deploy in under an hour.</p>"},{"location":"#why-this-exists","title":"Why This Exists","text":"<p>Modern data pipelines fail silently.</p> <p>By the time a dashboard is wrong:</p> <ul> <li>raw data is gone</li> <li>retries are invisible</li> <li>aggregates have overwritten history</li> </ul> <p>This project solves that by introducing immutable capture + controlled replay.</p>"},{"location":"#what-this-toolkit-is","title":"What This Toolkit Is","text":"<ul> <li>\u2714 Immutable raw event storage</li> <li>\u2714 Idempotent ingestion</li> <li>\u2714 Fine-grained replay by entity &amp; time window</li> <li>\u2714 Safe, opt-in processing</li> <li>\u2714 Full observability (logs + metrics)</li> <li>\u2714 Designed for debugging, not throughput</li> </ul>"},{"location":"#what-this-toolkit-is-not","title":"What This Toolkit Is NOT","text":"<ul> <li>\u2718 Not a streaming platform</li> <li>\u2718 Not a full ETL system</li> <li>\u2718 Not a replacement for your data warehouse</li> <li>\u2718 Not a real-time analytics engine</li> </ul> <p>It complements your pipeline \u2014 it does not replace it.</p>"},{"location":"#high-level-architecture","title":"High-Level Architecture","text":"<p>Ingest \u2192 Store \u2192 Inspect \u2192 Replay \u2192 (Optionally) Process:</p> <ul> <li>Events are ingested once</li> <li>Raw data is stored immutably in S3</li> <li>Metadata is indexed in DynamoDB</li> <li>Replay selectively re-emits events</li> <li>Processor computes versioned aggregates (optional)</li> </ul> <p>Every step is independently observable and reversible.</p>"},{"location":"#typical-use-cases","title":"Typical Use Cases","text":"<ul> <li>Debugging missing daily aggregates</li> <li>Investigating delayed syncs</li> <li>Replaying historical data safely</li> <li>Auditing aggregate changes</li> <li>Understanding duplicate storms</li> </ul>"},{"location":"#design-principles","title":"Design Principles","text":"<ul> <li>Investigation first</li> <li>Immutability over mutation</li> <li>Observability over automation</li> <li>Safety over convenience</li> <li>Reversible by default</li> </ul> <p>If something looks \u201cinefficient\u201d, it is probably intentional.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Deploy with processor disabled:</p> <pre><code>sam deploy --guided\n</code></pre> <p>Start ingesting events immediately.</p> <p>Enable replay and processor only when needed.</p> <p>\ud83d\udc49 See Quickstart for a hands-on walkthrough.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Quickstart \u2192 get running fast</li> <li>Architecture \u2192 understand how it works</li> <li>Guide \u2192 operate and debug safely</li> <li>Services \u2192 API &amp; component details</li> <li>FAQ \u2192 common questions and pitfalls</li> </ul>"},{"location":"#who-this-is-for","title":"Who This Is For","text":"<ul> <li>Backend engineers</li> <li>Data engineers</li> <li>Platform teams</li> <li>On-call responders</li> <li>Anyone debugging \u201cimpossible\u201d data bugs</li> </ul> <p>If you\u2019ve ever said \u201cthe data just disappeared\u201d, this is for you.</p>"},{"location":"#open-source","title":"Open Source","text":"<ul> <li>MIT License</li> <li>Easy to fork</li> <li>Minimal AWS footprint</li> <li>Designed to be extended</li> </ul> <p>Contributions are welcome.</p> <p>\ud83d\udc49 See CONTRIBUTING.md</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcd8 Read the Quickstart</li> <li>\ud83e\udde0 Explore the Architecture</li> <li>\ud83d\udee0 Deploy in a dev environment</li> <li>\ud83d\udd0d Use it during your next incident</li> </ul> <p>Pipeline Investigation Kit Observe first. Replay safely. Understand the truth.</p>"},{"location":"contrib/","title":"Contributing to Pipeline Investigation Kit","text":"<p>First of all: thank you for considering contributing \ud83d\ude4c This project aims to stay simple, practical, and production-shaped.</p> <p>We welcome contributions that improve:</p> <ul> <li>debuggability</li> <li>clarity</li> <li>reliability</li> <li>developer experience</li> </ul>"},{"location":"contrib/#guiding-principles","title":"Guiding Principles","text":"<ol> <li> <p>Investigation-first    This is not a full data pipeline. Changes should help explain failures.</p> </li> <li> <p>Minimalism over features    Prefer small utilities over frameworks. Avoid heavy dependencies.</p> </li> <li> <p>Production-shaped, not over-engineered    Realistic defaults without unnecessary complexity.</p> </li> <li> <p>Local-first DX <code>sam local</code> must work without AWS credentials.</p> </li> </ol>"},{"location":"contrib/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contrib/#fork-clone","title":"Fork &amp; clone","text":"<pre><code>git clone https://github.com/degerahmet/pipeline-investigation-kit.git\ncd pipeline-investigation-kit\n</code></pre>"},{"location":"contrib/#create-a-branch","title":"Create a branch","text":"<pre><code>git checkout -b feat/short-description\n</code></pre>"},{"location":"contrib/#local-setup","title":"Local setup","text":"<pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt -r requirements-dev.txt\n</code></pre>"},{"location":"contrib/#run-tests","title":"Run tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"contrib/#code-style","title":"Code Style","text":"<ul> <li>Python 3.11+</li> <li>Explicit over clever</li> <li>Small, testable functions</li> </ul>"},{"location":"contrib/#testing","title":"Testing","text":"<ul> <li>New logic requires tests</li> <li>Tests live in <code>tests/unit</code></li> <li>No real AWS calls in tests</li> </ul>"},{"location":"contrib/#pull-requests","title":"Pull Requests","text":"<p>Explain why the change exists and mention trade-offs.</p> <p>Thanks for contributing \ud83d\udc99</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#1-how-to-run-the-api-locally","title":"1. How to run the API locally?","text":"<p>Use AWS SAM CLI to build and start the API locally:</p> <pre><code>sam build\nsam local start-api --env-vars env/local.json\n</code></pre>"},{"location":"faq/#2-how-to-enable-the-processor-after-deployment","title":"2. How to enable the processor after deployment?","text":"<p>Update the CloudFormation stack with <code>EnableProcessor</code> set to <code>true</code>:</p> <pre><code>sam deploy --parameter-overrides EnableProcessor=true\n</code></pre>"},{"location":"faq/#3-how-to-customize-the-event-schema","title":"3. How to customize the event schema?","text":"<p>Modify the event schema in the ingestion Lambda function code (<code>ingest/app.py</code>) and ensure downstream components are compatible.</p>"},{"location":"faq/#4-how-to-monitor-metrics-and-logs","title":"4. How to monitor metrics and logs?","text":"<p>Use Amazon CloudWatch to monitor logs and metrics emitted by the Lambda functions. Look for custom metrics like <code>IngestCount</code> and <code>DuplicateCount</code>.</p>"},{"location":"faq/#5-how-to-handle-duplicate-events","title":"5. How to handle duplicate events?","text":"<p>The ingestion Lambda uses an idempotency key to detect duplicates. Ensure that your events include a stable <code>idempotency_key</code> field.</p>"},{"location":"faq/#6-how-to-replay-events-for-a-specific-entity-and-time-window","title":"6. How to replay events for a specific entity and time window?","text":"<p>Use the replay API endpoint with the desired <code>entity_id</code>, <code>start_time</code>, and <code>end_time</code> parameters to fetch and enqueue events for processing.</p>"},{"location":"faq/#7-how-to-test-the-entire-flow-end-to-end","title":"7. How to test the entire flow end-to-end?","text":"<p>Follow the quickstart guide to deploy the stack, ingest events, verify deduplication, replay events, and optionally enable processing.</p>"},{"location":"faq/#8-how-to-contribute-to-the-project","title":"8. How to contribute to the project?","text":"<p>See the CONTRIBUTING.md file for guidelines on how to contribute to the project.</p>"},{"location":"architecture/architecture/","title":"Architecture Diagram","text":""},{"location":"architecture/architecture/#diagrams","title":"Diagrams","text":""},{"location":"architecture/architecture/#producer","title":"Producer","text":"<pre><code>                +----------------------+\nProducer(s) ---&gt;| API Gateway (REST)   |\n                |  /ingest   /replay   |\n                +----------+-----------+\n                           |\n                           v\n                    +------+------+\n                    | Ingest Lambda|\n                    | (idempotent) |\n                    +---+------+---+\n                        |      |\n                        |      |  put_item / query\n                        |      v\n                        |   +--+-------------------+\n                        |   | DynamoDB (indexes)   |\n                        |   | EventsTable          |\n                        |   | DedupeTable          |\n                        |   +----------------------+\n                        |\n                        |  put_object (immutable)\n                        v\n                +-------+--------+\n                | S3 Raw Bucket  |\n                | raw/...        |\n                +----------------+\n</code></pre>"},{"location":"architecture/architecture/#investigator","title":"Investigator","text":"<pre><code>                           +-------------------+\n                           | Replay Lambda     |\nInvestigator --------------| query EventsTable |\n    (POST /replay)         | send SQS messages |\n                           +---------+---------+\n                                     |\n                                     v\n                              +------+------+\n                              |  SQS Queue  |\n                              | ReplayQueue |\n                              +------+------+\n                                     |\n                                     v\n                           +---------+----------+\n                           | Processor Lambda   |\n                           | (optional)         |\n                           | get_object from S3 |\n                           | put_item aggregates|\n                           +---------+---------+\n                                     |\n                                     v\n                           +---------+---------+\n                           | DynamoDB          |\n                           | AggregatesTable   |\n                           +-------------------+\n</code></pre>"},{"location":"architecture/architecture/#processor-lambda-flow","title":"Processor Lambda Flow","text":"<pre><code>                              +--------------+\n                              |  SQS Queue   |\n                              | ReplayQueue  |\n                              +------+-------+\n                                     |\n                                     | poll messages\n                                     v\n                           +---------+----------+\n                           | Processor Lambda   |\n                           |                    |\n                           | 1. Parse SQS body  |\n                           |    (s3_bucket,     |\n                           |     s3_key)        |\n                           +---------+----------+\n                                     |\n                                     | get_object\n                                     v\n                              +------+------+\n                              | S3 Raw      |\n                              | Bucket      |\n                              +------+------+\n                                     |\n                                     | load raw JSON\n                                     v\n                           +---------+----------+\n                           | 2. Group by        |\n                           |    entity + day    |\n                           |                    |\n                           | 3. Build aggregate |\n                           |    - daily count   |\n                           |    - inputs hash   |\n                           |    - sample IDs    |\n                           +---------+----------+\n                                     |\n                                     | put_item\n                                     v\n                              +------+-------+\n                              | DynamoDB     |\n                              | Aggregates   |\n                              | Table        |\n                              +--------------+\n                                     |\n                                     | emit metrics\n                                     v\n                              +------+-------+\n                              | CloudWatch   |\n                              | Metrics/Logs |\n                              +--------------+\n</code></pre>"},{"location":"architecture/architecture/#why-this-layout","title":"Why this layout?","text":"<ul> <li>S3 is the source of truth for raw payloads (cheap, immutable, queryable later via Athena if desired).</li> <li>DynamoDB is the investigation index: fast lookups by entity/time window and by source/type/day.</li> <li>SQS decouples replay from processing and allows controlled reprocessing at scale.</li> <li>Lambda keeps deployment simple and portable across teams.</li> </ul>"},{"location":"architecture/deployment/","title":"Deployment Architecture (AWS SAM)","text":"<p>This kit deploys with AWS SAM into a single stack:</p>"},{"location":"architecture/deployment/#resources","title":"Resources","text":""},{"location":"architecture/deployment/#api-gateway","title":"API Gateway","text":"<p>REST API with two endpoints:</p> <ul> <li><code>POST /ingest</code> \u2192 Ingest Lambda</li> <li><code>POST /replay</code> \u2192 Replay Lambda</li> </ul>"},{"location":"architecture/deployment/#storage","title":"Storage","text":"<ul> <li>S3 Bucket: Immutable raw event payloads</li> <li>DynamoDB Tables:<ul> <li><code>EventsTable</code>: Metadata and index records</li> <li><code>DedupeTable</code>: Idempotency gate for duplicate detection</li> <li><code>AggregatesTable</code>: Versioned aggregate results (optional, only when <code>EnableProcessor=true</code>)</li> </ul> </li> </ul>"},{"location":"architecture/deployment/#messaging","title":"Messaging","text":"<ul> <li>SQS Queue: <code>ReplayQueue</code> for event reprocessing</li> </ul>"},{"location":"architecture/deployment/#compute","title":"Compute","text":"<p>Lambda Functions:</p> <ul> <li><code>IngestFunction</code>: Validates and stores incoming events</li> <li><code>ReplayFunction</code>: Queries and replays historical events</li> <li><code>ProcessorFunction</code>: Consumes and processes events from SQS (optional)</li> </ul>"},{"location":"architecture/deployment/#parameters","title":"Parameters","text":"<ul> <li><code>EnableProcessor</code> (bool)</li> <li><code>false</code>: no processor / no aggregates table / no event source mapping</li> <li><code>true</code>: creates Processor + AggregatesTable and wires SQS \u2192 Processor</li> </ul>"},{"location":"architecture/deployment/#environments","title":"Environments","text":"<p>Each Lambda receives env vars for resource names/urls:</p> <ul> <li><code>RAW_BUCKET</code></li> <li><code>EVENTS_TABLE</code></li> <li><code>DEDUPE_TABLE</code></li> <li><code>REPLAY_QUEUE_URL</code></li> <li><code>AGG_TABLE</code> (processor only)</li> <li><code>LOG_LEVEL</code></li> </ul>"},{"location":"architecture/deployment/#iam","title":"IAM","text":"<p>Each Lambda has a dedicated role with least-privilege access:</p> <ul> <li>Ingest: PutObject to raw bucket, PutItem to tables, PutMetricData/logging</li> <li>Replay: Query EventsTable, SendMessage to SQS</li> <li>Processor: GetObject from raw bucket, PutItem to AggregatesTable</li> </ul>"},{"location":"architecture/deployment/#components-in-this-stack","title":"Components in this stack","text":"<ul> <li>API Gateway (REST)</li> <li>Lambda (Ingest, Replay, optional Processor)</li> <li>DynamoDB (EventsTable, DedupeTable, optional AggregatesTable)</li> <li>S3 (raw immutable storage)</li> <li>SQS (ReplayQueue)</li> <li>CloudWatch (logs + EMF metrics)</li> <li>IAM (least privilege roles)</li> <li>X-Ray (tracing)</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>This project is an investigation + observability kit for data pipelines: it captures immutable raw events, indexes them for fast querying, measures lag, detects duplicates, and supports replay into a queue for downstream processing.</p> <p>It is intentionally production-shaped, but not a full ETL/warehouse pipeline.</p>"},{"location":"architecture/overview/#core-goals","title":"Core Goals","text":"<ul> <li>Immutable raw storage: keep the original event payloads as they arrived.</li> <li>Idempotent ingestion: stable <code>event_id</code>, dedupe gate, safe retries.</li> <li>Fast investigation: query by entity/time windows, find gaps/late arrivals, see which sources/types are problematic.</li> <li>Replay: push historical events back into a queue for reprocessing.</li> <li>Traceability: aggregate outputs store input hashes and sample event_ids.</li> </ul>"},{"location":"architecture/overview/#high-level-flow","title":"High-level flow","text":""},{"location":"architecture/overview/#1-event-ingestion","title":"1. Event Ingestion","text":"<p>Producer \u2192 Ingest API (<code>POST /ingest</code>)</p> <ul> <li>Validates incoming event payload</li> <li>Computes stable <code>event_id</code> (for idempotency)</li> <li>Writes to three destinations:<ol> <li>S3: Raw JSON with immutable object key</li> <li>DynamoDB: Metadata and index records for fast querying</li> <li>CloudWatch: Metrics and structured logs</li> </ol> </li> </ul>"},{"location":"architecture/overview/#2-investigation-replay","title":"2. Investigation &amp; Replay","text":"<p>Investigator \u2192 Replay API (<code>POST /replay</code>)</p> <ul> <li>Queries DynamoDB for historical events (by entity, time range, etc.)</li> <li>Sends selected events to SQS queue for reprocessing</li> </ul>"},{"location":"architecture/overview/#3-event-processing-optional","title":"3. Event Processing (Optional)","text":"<p>Processor Lambda \u2190 SQS Queue</p> <ol> <li>Loads raw event from S3</li> <li>Normalizes data to minimal schema</li> <li>Computes placeholder aggregate</li> <li>Stores versioned results with input hashes for auditability</li> </ol>"},{"location":"architecture/overview/#key-extension-points","title":"Key extension points","text":"<ul> <li>Schema: extend allowed fields / validation in <code>src/shared/schema.py</code></li> <li>Partitioning: change S3 key layout and DynamoDB PK/SK format in shared utilities</li> <li>Replay output: customize message payload for your downstream processors</li> <li>Processor: replace placeholder aggregates with domain logic; keep input hashes for auditability</li> </ul>"},{"location":"architecture/components/apigateway/","title":"API Gateway","text":"<p>We expose a minimal REST API for investigation workflows.</p>"},{"location":"architecture/components/apigateway/#endpoints","title":"Endpoints","text":"<ul> <li> <p><code>POST /ingest</code> \u2192 Ingest Lambda   Used by producers to submit raw events.</p> </li> <li> <p><code>POST /replay</code> \u2192 Replay Lambda   Used by investigators to replay events for an entity + time window.</p> </li> </ul>"},{"location":"architecture/components/apigateway/#why-api-gateway-here","title":"Why API Gateway here?","text":"<ul> <li>Standard HTTP interface teams can hit with curl/Postman.</li> <li>Easy to secure later (API keys, IAM auth, Cognito, Lambda authorizer).</li> <li>Works well for \"deploy fast, investigate now\" workflows.</li> </ul>"},{"location":"architecture/components/apigateway/#current-security-posture","title":"Current security posture","text":"<p>By default, the generated API may be public. For open-source defaults, we keep it simple, but production teams should enable: - auth (IAM/Cognito/authorizer) - throttling / rate limits - request validation + WAF if internet-facing</p>"},{"location":"architecture/components/cloudwatch/","title":"CloudWatch","text":"<p>We use CloudWatch for:</p> <ul> <li>structured logs</li> <li>custom metrics via EMF (Embedded Metric Format)</li> </ul>"},{"location":"architecture/components/cloudwatch/#logs","title":"Logs","text":"<p>Each Lambda writes JSON logs to:</p> <ul> <li><code>/aws/lambda/&lt;FunctionName&gt;</code></li> </ul> <p>These logs support quick investigation in CloudWatch Logs Insights.</p>"},{"location":"architecture/components/cloudwatch/#metrics-emf","title":"Metrics (EMF)","text":"<p>Namespace: <code>PipelineInvestigationKit</code></p> <p>Examples emitted by the functions:</p> <ul> <li>Ingest: <code>IngestLagMs</code>, <code>DuplicateCount</code>, <code>IngestAcceptedCount</code></li> <li>Replay: <code>ReplayRequestedCount</code>, <code>ReplayMessageCount</code></li> <li>Processor: <code>ProcessorMessageCount</code>, <code>ProcessorErrorCount</code></li> </ul>"},{"location":"architecture/components/cloudwatch/#why-emf","title":"Why EMF?","text":"<ul> <li>No separate <code>PutMetricData</code> calls (cheaper/simpler).</li> <li>Metrics show up automatically from logs.</li> <li>Easy to build dashboards and alarms.</li> </ul>"},{"location":"architecture/components/cloudwatch/#next-steps-for-teams","title":"Next steps (for teams)","text":"<ul> <li>Create alarms on error counts and lag percentiles.</li> <li>Add a dashboard grouping ingest/replay/processor metrics.</li> </ul>"},{"location":"architecture/components/dynamodb/","title":"DynamoDB","text":"<p>We use DynamoDB as the investigation index (not as the raw payload store).</p>"},{"location":"architecture/components/dynamodb/#tables","title":"Tables","text":""},{"location":"architecture/components/dynamodb/#eventstable","title":"EventsTable","text":"<p>Stores metadata per event:</p> <ul> <li><code>PK = ENTITY#&lt;entity_id&gt;</code></li> <li><code>SK = TS#&lt;event_time&gt;#EID#&lt;event_id&gt;</code> Used to query: \u201cfor this entity, show events between start/end\u201d.</li> </ul> <p>Also includes a GSI for \u201csource/type/day\u201d analysis:</p> <ul> <li><code>GSI1PK = SRC#&lt;source&gt;#TYPE#&lt;event_type&gt;#DAY#&lt;YYYY-MM-DD&gt;</code></li> <li><code>GSI1SK = LAG#&lt;lag_ms&gt;#TS#&lt;ingest_time&gt;#EID#&lt;event_id&gt;</code></li> </ul>"},{"location":"architecture/components/dynamodb/#dedupetable","title":"DedupeTable","text":"<p>Idempotency gate:</p> <ul> <li><code>PK = EVENT#&lt;event_id&gt;</code> A conditional put ensures the first occurrence wins.</li> </ul>"},{"location":"architecture/components/dynamodb/#aggregatestable-optional","title":"AggregatesTable (optional)","text":"<p>Versioned aggregates: - <code>PK = ENTITY#&lt;entity_id&gt;</code> - <code>SK = DAY#&lt;YYYY-MM-DD&gt;#VER#&lt;unix_ts&gt;</code> Store: - <code>inputs_hash</code> - <code>input_count</code> - <code>sample_event_ids</code></p>"},{"location":"architecture/components/dynamodb/#common-customizations","title":"Common customizations","text":"<ul> <li>Add a GSI for: \u201cfind missing windows per day\u201d</li> <li>Add TTL on DedupeTable to limit storage (e.g., 30\u201390 days)</li> </ul>"},{"location":"architecture/components/iam/","title":"IAM","text":"<p>Each Lambda has a dedicated IAM role with least-privilege policies.</p>"},{"location":"architecture/components/iam/#ingestfunction-role","title":"IngestFunction Role","text":"<p>Typically needs:</p> <ul> <li><code>s3:PutObject</code> to raw bucket</li> <li><code>dynamodb:PutItem</code> / <code>dynamodb:UpdateItem</code> (and <code>DescribeTable</code>) for Events/Dedupe tables</li> <li>CloudWatch Logs permissions (basic execution role)</li> <li>(optional) X-Ray write</li> </ul>"},{"location":"architecture/components/iam/#replayfunction-role","title":"ReplayFunction Role","text":"<p>Typically needs:</p> <ul> <li><code>dynamodb:Query</code> on EventsTable (+ index/*)</li> <li><code>sqs:SendMessage</code> to ReplayQueue</li> <li>CloudWatch Logs permissions</li> <li>(optional) X-Ray write</li> </ul>"},{"location":"architecture/components/iam/#processorfunction-role-optional","title":"ProcessorFunction Role (optional)","text":"<p>Typically needs:</p> <ul> <li><code>s3:GetObject</code> from raw bucket</li> <li><code>dynamodb:PutItem</code> to AggregatesTable</li> <li><code>sqs:ReceiveMessage/DeleteMessage</code> via event source mapping</li> <li>CloudWatch Logs permissions</li> <li>(optional) X-Ray write</li> </ul>"},{"location":"architecture/components/iam/#guidance","title":"Guidance","text":"<ul> <li>Avoid wildcard actions/resources unless unavoidable.</li> <li>Prefer table ARN + <code>/index/*</code> where needed.</li> <li>Treat these roles as the \"security contract\" for the repo.</li> </ul>"},{"location":"architecture/components/lambda/","title":"Lambda","text":"<p>There are three functions.</p>"},{"location":"architecture/components/lambda/#ingestfunction","title":"IngestFunction","text":"<p>Responsibilities:</p> <ul> <li>validate minimal schema</li> <li>compute stable <code>event_id</code></li> <li>dedupe gate (DynamoDB conditional put)</li> <li>write raw JSON to S3 (immutable key)</li> <li>write metadata index to EventsTable</li> <li>emit metrics (EMF)</li> </ul>"},{"location":"architecture/components/lambda/#replayfunction","title":"ReplayFunction","text":"<p>Responsibilities:</p> <ul> <li>query EventsTable by <code>entity_id</code> + time window</li> <li>build replay messages</li> <li>send to SQS</li> <li>emit metrics (requested vs sent)</li> </ul>"},{"location":"architecture/components/lambda/#processorfunction-optional","title":"ProcessorFunction (optional)","text":"<p>Responsibilities:</p> <ul> <li>consume SQS messages</li> <li>fetch raw object from S3</li> <li>normalize minimal schema</li> <li>compute placeholder aggregate and store versioned outputs</li> <li>emit metrics (processed/errors)</li> </ul>"},{"location":"architecture/components/lambda/#operational-notes","title":"Operational notes","text":"<ul> <li>keep handlers thin; push logic into <code>src/*/logic.py</code></li> <li>prefer deterministic outputs for testability.</li> </ul>"},{"location":"architecture/components/s3/","title":"S3","text":"<p>S3 stores immutable raw event payloads.</p>"},{"location":"architecture/components/s3/#raw-layout","title":"Raw layout","text":"<p>Default key format (partition-friendly):</p> <p>raw/source=/event_type=/event_date=/ingest_date=/hour=/event_id=.json <p>This supports:</p> <ul> <li>ad-hoc Athena queries later</li> <li>easy browsing by day/source/type</li> <li>investigations by ingest-time vs event-time</li> </ul>"},{"location":"architecture/components/s3/#immutability","title":"Immutability","text":"<p>We never overwrite existing objects:</p> <ul> <li>same event_id \u2192 same key</li> <li>duplicates do not write again (dedupe gate)</li> </ul>"},{"location":"architecture/components/s3/#recommended-defaults","title":"Recommended defaults","text":"<ul> <li>SSE-S3 or SSE-KMS</li> <li>lifecycle policy (e.g., raw events keep 30\u2013180 days depending on needs)</li> </ul>"},{"location":"architecture/components/sam/","title":"AWS SAM","text":"<p>This repo uses AWS SAM to keep infra small and reproducible.</p>"},{"location":"architecture/components/sam/#why-sam","title":"Why SAM?","text":"<ul> <li>one template (<code>template.yaml</code>)</li> <li>local iteration (<code>sam local start-api</code>)</li> <li>guided deploy (<code>sam deploy --guided</code>)</li> <li>parameterized optional processor (<code>EnableProcessor</code>)</li> </ul>"},{"location":"architecture/components/sam/#where-to-look","title":"Where to look","text":"<ul> <li><code>template.yaml</code>: resources + IAM + env vars</li> <li><code>.github/workflows/*</code> (if you add CI/CD later)</li> </ul>"},{"location":"architecture/components/sqs/","title":"SQS","text":"<p>SQS provides a simple replay buffer between investigation and processing.</p>"},{"location":"architecture/components/sqs/#replayqueue","title":"ReplayQueue","text":"<p>Replay Lambda sends one message per event:</p> <pre><code>{\n  \"event_id\": \"...\",\n  \"entity_id\": \"...\",\n  \"event_time\": \"2025-12-28T23:59:59Z\",\n  \"s3_bucket\": \"...\",\n  \"s3_key\": \"raw/source=.../event_id=....json\"\n}\n</code></pre>"},{"location":"architecture/components/sqs/#why-sqs","title":"Why SQS?","text":"<ul> <li>Decouples replay from processing.</li> <li>Lets you scale the processor independently.</li> <li>Provides backpressure and retry behavior.</li> </ul>"},{"location":"architecture/components/sqs/#notes","title":"Notes","text":"<ul> <li>Processor is optional (EnableProcessor=true wires SQS \u2192 Processor Lambda).</li> <li>If processor is disabled, SQS still collects replay messages for external consumers.</li> </ul>"},{"location":"architecture/components/xray/","title":"X-Ray","text":"<p>We enable X-Ray to trace requests across API Gateway \u2192 Lambda and AWS SDK calls.</p>"},{"location":"architecture/components/xray/#what-it-helps-with","title":"What it helps with","text":"<ul> <li>\"Why is this request slow?\"</li> <li>\"Which dependency call is failing?\" (DynamoDB/S3/SQS)</li> <li>End-to-end visibility when debugging incidents</li> </ul>"},{"location":"architecture/components/xray/#notes","title":"Notes","text":"<ul> <li>X-Ray is helpful during investigations but optional for minimal stacks.</li> <li>Keep sampling reasonable in production environments.</li> </ul>"},{"location":"guide/configuration/","title":"Developer Guide \u2013 Configuration","text":"<p>This section explains all runtime configuration options, how they affect behavior, and which ones you are expected to customize.</p> <p>The system follows a strict rule:</p> <p>Configuration controls behavior, not code.</p>"},{"location":"guide/configuration/#configuration-model","title":"Configuration Model","text":"<p>All configuration is done via environment variables.</p> <p>These are injected by:</p> <ul> <li>AWS SAM</li> <li>CloudFormation</li> <li><code>sam local invoke --env-vars</code></li> </ul> <p>There are no hard-coded environment-specific values in the code.</p>"},{"location":"guide/configuration/#required-environment-variables","title":"Required Environment Variables","text":"<p>These are injected automatically by the SAM template.</p> <p>You should never manually set them in production.</p>"},{"location":"guide/configuration/#storage-state","title":"Storage &amp; State","text":"Variable Purpose <code>RAW_BUCKET</code> S3 bucket for immutable raw events <code>EVENTS_TABLE</code> DynamoDB table for event metadata <code>DEDUPE_TABLE</code> DynamoDB table for idempotency <code>AGG_TABLE</code> DynamoDB table for aggregates <code>REPLAY_QUEUE_URL</code> SQS queue for replay"},{"location":"guide/configuration/#execution-mode-flags","title":"Execution Mode Flags","text":""},{"location":"guide/configuration/#dry_run","title":"<code>DRY_RUN</code>","text":"<pre><code>DRY_RUN=true | false\n</code></pre> <p>Most important flag in the system.</p> <p>Controls whether the system:</p> <ul> <li>writes data</li> <li>sends messages</li> <li>mutates state</li> </ul>"},{"location":"guide/configuration/#behavior","title":"Behavior","text":"Component DRY_RUN=true DRY_RUN=false Ingest validates only writes S3 + DynamoDB Replay scans only sends SQS messages Processor counts only writes aggregates"},{"location":"guide/configuration/#why-dry_run-exists","title":"Why DRY_RUN exists","text":"<ul> <li>safe local testing</li> <li>safe production investigation</li> <li>zero-risk replay analysis</li> </ul> <p>Default: <code>false</code></p>"},{"location":"guide/configuration/#log_level","title":"<code>LOG_LEVEL</code>","text":"<pre><code>LOG_LEVEL=INFO | DEBUG\n</code></pre> <p>Controls log verbosity.</p> <ul> <li><code>INFO</code> \u2192 normal operation</li> <li><code>DEBUG</code> \u2192 investigations only</li> </ul> <p>Avoid <code>DEBUG</code> in production for cost reasons.</p>"},{"location":"guide/configuration/#feature-toggles","title":"Feature Toggles","text":""},{"location":"guide/configuration/#enableprocessor-sam-parameter","title":"<code>EnableProcessor</code> (SAM Parameter)","text":"<p>This is a deployment-time toggle, not a runtime env var.</p> <pre><code>sam deploy --parameter-overrides EnableProcessor=true\n</code></pre> <p>Controls:</p> <ul> <li>creation of Processor Lambda</li> <li>creation of SQS event source mapping</li> </ul> <p>This is the safest kill switch in the system.</p>"},{"location":"guide/configuration/#replay-configuration","title":"Replay Configuration","text":"<p>Replay behavior is controlled per-request.</p>"},{"location":"guide/configuration/#replay-request-fields","title":"Replay Request Fields","text":"Field Description <code>entity_id</code> Entity to replay <code>start_time</code> ISO-8601 start <code>end_time</code> ISO-8601 end <code>limit</code> Max messages <code>include_duplicates</code> Include duplicates or not <p>Replay never mutates data by itself.</p>"},{"location":"guide/configuration/#aggregate-versioning","title":"Aggregate Versioning","text":"<p>Aggregates are versioned automatically.</p> <p>Each aggregate row includes:</p> <ul> <li><code>inputs_hash</code></li> <li><code>computed_at</code></li> <li><code>VER#&lt;timestamp&gt;</code> in sort key</li> </ul> <p>This allows:</p> <ul> <li>reprocessing</li> <li>comparison</li> <li>rollback</li> <li>auditability</li> </ul> <p>No configuration needed.</p>"},{"location":"guide/configuration/#iam-configuration","title":"IAM Configuration","text":"<p>IAM permissions are least-privilege by default.</p> <p>Each Lambda has:</p> <ul> <li>its own role</li> <li>scoped access</li> <li>no wildcard writes</li> </ul> <p>You should not extend IAM unless adding new components.</p>"},{"location":"guide/configuration/#local-configuration","title":"Local Configuration","text":"<p>For local testing:</p> <pre><code>sam local invoke IngestFunction \\\n  --env-vars env/local.json\n</code></pre> <p>Example <code>env/local.json</code>:</p> <pre><code>{\n  \"IngestFunction\": {\n    \"DRY_RUN\": \"true\",\n    \"LOG_LEVEL\": \"DEBUG\"\n  }\n}\n</code></pre> <p>Never commit real secrets.</p>"},{"location":"guide/configuration/#configuration-anti-patterns","title":"Configuration Anti-Patterns","text":""},{"location":"guide/configuration/#hardcoding-resource-names","title":"\u274c Hardcoding Resource Names","text":"<p>Breaks:</p> <ul> <li>environments</li> <li>deployments</li> <li>portability</li> </ul>"},{"location":"guide/configuration/#using-code-flags-instead-of-env-vars","title":"\u274c Using Code Flags Instead of Env Vars","text":"<p>Configuration must be:</p> <ul> <li>observable</li> <li>changeable</li> <li>reversible</li> </ul>"},{"location":"guide/configuration/#running-without-dry_run-first","title":"\u274c Running Without DRY_RUN First","text":"<p>Always validate behavior before mutating state.</p>"},{"location":"guide/configuration/#configuration-checklist","title":"Configuration Checklist","text":"<p>Before production use:</p> <ul> <li>[ ] DRY_RUN tested</li> <li>[ ] Processor disabled initially</li> <li>[ ] LOG_LEVEL set correctly</li> <li>[ ] Replay tested</li> <li>[ ] IAM untouched</li> </ul>"},{"location":"guide/configuration/#next-usage","title":"Next: Usage","text":"<p>Next we\u2019ll cover:</p> <ul> <li>normal operation</li> <li>investigation workflows</li> <li>replay patterns</li> <li>real-world examples</li> </ul> <p>\ud83d\udc49 Continue with Guide \u2192 Usage</p>"},{"location":"guide/deployment/","title":"Developer Guide \u2013 Deployment","text":"<p>This section explains how to deploy the Pipeline Investigation Kit safely, and more importantly, why the deployment is structured this way.</p> <p>The deployment strategy prioritizes:</p> <ul> <li>safety</li> <li>reversibility</li> <li>observability</li> </ul>"},{"location":"guide/deployment/#deployment-model","title":"Deployment Model","text":"<p>The project is deployed using AWS SAM (Serverless Application Model).</p> <p>All infrastructure is defined in a single <code>template.yaml</code>, including:</p> <ul> <li>APIs</li> <li>Lambda functions</li> <li>DynamoDB tables</li> <li>S3 bucket</li> <li>SQS queue</li> <li>IAM roles</li> <li>event source mappings</li> </ul> <p>There is no manual AWS setup required.</p>"},{"location":"guide/deployment/#environments","title":"Environments","text":"<p>The system is environment-aware by design.</p> <p>Typical environments:</p> <ul> <li><code>dev</code></li> <li><code>staging</code></li> <li><code>prod</code></li> </ul> <p>Each environment gets:</p> <ul> <li>isolated DynamoDB tables</li> <li>isolated S3 bucket</li> <li>isolated SQS queue</li> <li>isolated API Gateway stage</li> </ul> <p>This prevents cross-environment data leakage.</p>"},{"location":"guide/deployment/#first-time-deployment","title":"First-Time Deployment","text":"<p>Initial deployment should always be done with the processor disabled.</p> <pre><code>sam deploy --guided\n</code></pre> <p>When prompted for parameters:</p> <pre><code>EnableProcessor = false\n</code></pre>"},{"location":"guide/deployment/#why","title":"Why?","text":"<p>Because:</p> <ul> <li>ingest and replay are safe without processing</li> <li>processor consumes messages automatically</li> <li>enabling it too early removes control</li> </ul> <p>You want to observe before acting.</p>"},{"location":"guide/deployment/#incremental-enablement-strategy","title":"Incremental Enablement Strategy","text":"<p>Deployment is intentionally split into phases.</p>"},{"location":"guide/deployment/#phase-1-ingest-only","title":"Phase 1 \u2013 Ingest Only","text":"<p>Enabled:</p> <ul> <li>Ingest API</li> <li>DynamoDB metadata tables</li> <li>S3 raw storage</li> </ul> <p>Disabled:</p> <ul> <li>Processor</li> <li>Event source mapping</li> </ul> <p>This allows you to verify:</p> <ul> <li>API works</li> <li>deduplication works</li> <li>raw data is stored correctly</li> </ul>"},{"location":"guide/deployment/#phase-2-replay-enabled","title":"Phase 2 \u2013 Replay Enabled","text":"<p>Enabled:</p> <ul> <li>Replay API</li> <li>SQS queue</li> </ul> <p>Still disabled:</p> <ul> <li>Processor</li> </ul> <p>This allows:</p> <ul> <li>replay requests</li> <li>queue inspection</li> <li>message validation</li> </ul> <p>You should manually inspect SQS messages at this stage.</p>"},{"location":"guide/deployment/#phase-3-processor-enabled","title":"Phase 3 \u2013 Processor Enabled","text":"<p>Only after verification:</p> <pre><code>sam deploy --parameter-overrides EnableProcessor=true\n</code></pre> <p>This:</p> <ul> <li>creates the Processor Lambda</li> <li>attaches the SQS event source mapping</li> <li>begins automatic consumption</li> </ul> <p>At this point the system is fully live.</p>"},{"location":"guide/deployment/#safe-rollback-strategy","title":"Safe Rollback Strategy","text":"<p>If something goes wrong:</p>"},{"location":"guide/deployment/#disable-processor-immediately","title":"Disable Processor Immediately","text":"<pre><code>sam deploy --parameter-overrides EnableProcessor=false\n</code></pre> <p>This:</p> <ul> <li>removes the event source mapping</li> <li>stops processing</li> <li>preserves queue messages</li> </ul> <p>No data is lost.</p>"},{"location":"guide/deployment/#deployment-is-idempotent","title":"Deployment Is Idempotent","text":"<p>You can safely re-run deploy commands.</p> <p>SAM + CloudFormation ensure:</p> <ul> <li>unchanged resources are not recreated</li> <li>data stores are preserved</li> <li>IAM roles are updated safely</li> </ul>"},{"location":"guide/deployment/#zero-downtime-behavior","title":"Zero-Downtime Behavior","text":"<p>The system is designed so that:</p> <ul> <li>APIs remain available during deploy</li> <li>SQS buffers messages</li> <li>processor restarts are safe</li> </ul> <p>Temporary delays do not cause data loss.</p>"},{"location":"guide/deployment/#common-deployment-mistakes","title":"Common Deployment Mistakes","text":""},{"location":"guide/deployment/#enabling-processor-too-early","title":"\u274c Enabling Processor Too Early","text":"<p>Symptoms:</p> <ul> <li>messages disappear unexpectedly</li> <li>aggregates look incorrect</li> <li>difficult debugging</li> </ul> <p>Fix:</p> <ul> <li>disable processor</li> <li>inspect replay output</li> <li>re-enable</li> </ul>"},{"location":"guide/deployment/#forgetting-environment-isolation","title":"\u274c Forgetting Environment Isolation","text":"<p>Symptoms:</p> <ul> <li>replay returns unexpected data</li> <li>mixed test and prod data</li> </ul> <p>Fix:</p> <ul> <li>verify stack name</li> <li>verify API URL</li> <li>verify table names</li> </ul>"},{"location":"guide/deployment/#deploying-without-observability","title":"\u274c Deploying Without Observability","text":"<p>Always verify:</p> <ul> <li>CloudWatch logs exist</li> <li>metrics are emitted</li> <li>DRY_RUN works</li> </ul> <p>If you can\u2019t observe it, don\u2019t deploy it.</p>"},{"location":"guide/deployment/#recommended-deployment-checklist","title":"Recommended Deployment Checklist","text":"<p>Before enabling processor:</p> <ul> <li>Ingest API responds correctly</li> <li>Duplicate events are detected</li> <li>Raw S3 objects exist</li> <li>Replay returns expected events</li> <li>SQS messages look correct</li> <li>DRY_RUN works end-to-end</li> </ul> <p>Only then enable processing.</p>"},{"location":"guide/deployment/#next-configuration","title":"Next: Configuration","text":"<p>Next we\u2019ll cover:</p> <ul> <li>environment variables</li> <li>execution modes</li> <li>DRY_RUN behavior</li> <li>tuning knobs</li> </ul> <p>\ud83d\udc49 Continue with Guide \u2192 Configuration</p>"},{"location":"guide/guide/","title":"Developer Guide \u2013 Overview","text":"<p>This guide explains how to work with the Pipeline Investigation Kit as a developer.</p> <p>It assumes:</p> <ul> <li>you can read Python</li> <li>you are comfortable with AWS concepts</li> <li>you want to understand the system, not just deploy it</li> </ul> <p>If you are only looking for a quick demo, see Quickstart.</p>"},{"location":"guide/guide/#what-this-project-is","title":"What This Project Is","text":"<p>Pipeline Investigation Kit is a debug-first, replayable data ingestion pipeline built on AWS serverless primitives.</p> <p>It is designed to answer questions like:</p> <ul> <li>What exactly happened to this event?</li> <li>Was it ingested?</li> <li>Was it deduplicated?</li> <li>Was it processed?</li> <li>Can we replay it safely?</li> </ul> <p>The system favors observability and determinism over raw throughput.</p>"},{"location":"guide/guide/#what-this-project-is-not","title":"What This Project Is NOT","text":"<p>This project is not:</p> <ul> <li>a real-time streaming system</li> <li>a generic ETL framework</li> <li>a batch analytics engine</li> <li>a low-latency event processor</li> </ul> <p>Those trade-offs are intentional.</p>"},{"location":"guide/guide/#core-design-goals","title":"Core Design Goals","text":""},{"location":"guide/guide/#1-every-event-is-explainable","title":"1. Every Event Is Explainable","text":"<p>For any event, you should be able to reconstruct:</p> <ul> <li>when it arrived</li> <li>how late it was</li> <li>where it was stored</li> <li>whether it was deduplicated</li> <li>whether it was processed</li> <li>what output it produced</li> </ul> <p>If an event cannot be explained, the system has failed.</p>"},{"location":"guide/guide/#2-replay-is-a-first-class-feature","title":"2. Replay Is a First-Class Feature","text":"<p>Replay is not an afterthought.</p> <p>The pipeline is explicitly designed so that:</p> <ul> <li>raw data is immutable</li> <li>metadata is queryable</li> <li>processing is repeatable</li> </ul> <p>Replay is safe by default.</p>"},{"location":"guide/guide/#3-idempotency-everywhere","title":"3. Idempotency Everywhere","text":"<p>All writes are designed to tolerate retries:</p> <ul> <li>ingest deduplication is explicit</li> <li>replay can re-enqueue safely</li> <li>processor logic tolerates duplicates</li> <li>aggregation is deterministic</li> </ul> <p>You should never fear re-running a step.</p>"},{"location":"guide/guide/#4-dry_run-is-production-grade","title":"4. DRY_RUN Is Production-Grade","text":"<p><code>DRY_RUN=true</code> means:</p> <ul> <li>full logic execution</li> <li>no external side effects</li> <li>metrics are still emitted</li> </ul> <p>This allows:</p> <ul> <li>local debugging</li> <li>production safety checks</li> <li>incident simulation</li> </ul>"},{"location":"guide/guide/#high-level-flow","title":"High-Level Flow","text":"<p>At a high level, the system works like this:</p> <ol> <li> <p>Ingest</p> </li> <li> <p>receives an event via HTTP</p> </li> <li>computes event identity</li> <li>stores raw payload immutably</li> <li>writes metadata</li> <li> <p>performs deduplication</p> </li> <li> <p>Replay</p> </li> <li> <p>queries historical events</p> </li> <li>applies filtering rules</li> <li> <p>enqueues replay messages</p> </li> <li> <p>Processor</p> </li> <li> <p>consumes replay messages</p> </li> <li>reads raw data from storage</li> <li>computes aggregates</li> <li>writes deterministic outputs</li> </ol> <p>Each stage is isolated and independently testable.</p>"},{"location":"guide/guide/#mental-model-for-developers","title":"Mental Model for Developers","text":"<p>When working on this project, always ask:</p> <ul> <li>Is this operation safe to retry?</li> <li>Can I explain this behavior later?</li> <li>Does this reduce or increase observability?</li> <li>Would DRY_RUN behave sensibly here?</li> </ul> <p>If the answer is unclear, stop and rethink.</p>"},{"location":"guide/guide/#how-the-guide-is-organized","title":"How the Guide Is Organized","text":"<p>This guide is split into focused sections:</p> <ul> <li> <p>Deployment   How the system is deployed and toggled safely.</p> </li> <li> <p>Configuration   Environment variables, flags, and execution modes.</p> </li> <li> <p>Usage   How to interact with the APIs and queues.</p> </li> <li> <p>Troubleshooting   How to debug real production issues.</p> </li> </ul> <p>Each section assumes you\u2019ve read this overview.</p>"},{"location":"guide/guide/#who-this-guide-is-for","title":"Who This Guide Is For","text":"<p>This guide is written for:</p> <ul> <li>backend engineers</li> <li>platform engineers</li> <li>data engineers debugging pipelines</li> <li>anyone who has ever asked   \u201cWhy did this event disappear?\u201d</li> </ul>"},{"location":"guide/guide/#next-deployment","title":"Next: Deployment","text":"<p>Next, we\u2019ll cover Deployment, including:</p> <ul> <li>environment strategy</li> <li>enabling / disabling processor safely</li> <li>rollout patterns</li> <li>common deployment mistakes</li> </ul> <p>\ud83d\udc49 Continue with Guide \u2192 Deployment</p>"},{"location":"guide/troubleshooting/","title":"Developer Guide \u2013 Troubleshooting","text":"<p>This section documents real failure modes you are likely to see, how to diagnose them, and what not to do.</p> <p>This project is intentionally transparent: if something looks wrong, the system is probably telling you something important.</p>"},{"location":"guide/troubleshooting/#core-troubleshooting-principle","title":"Core Troubleshooting Principle","text":"<p>Never \u201cfix\u201d before you understand.</p> <p>Use:</p> <ul> <li>logs</li> <li>metrics</li> <li>raw data</li> <li>replay</li> </ul> <p>Do not patch blindly.</p>"},{"location":"guide/troubleshooting/#ingest-issues","title":"Ingest Issues","text":""},{"location":"guide/troubleshooting/#ingest-returns-duplicate-unexpectedly","title":"\u2757 Ingest returns <code>DUPLICATE</code> unexpectedly","text":"<p>This is not an error.</p> <p>Likely causes:</p> <ul> <li>client retries</li> <li>network timeouts</li> <li>upstream replay</li> </ul> <p>What to check:</p> <ul> <li>same <code>event_id</code></li> <li>same payload hash</li> <li>dedupe table entries</li> </ul> <p>\u2705 Expected behavior.</p>"},{"location":"guide/troubleshooting/#ingest-accepts-but-no-data-appears-downstream","title":"\u2757 Ingest accepts but no data appears downstream","text":"<p>Check:</p> <ol> <li>S3 bucket \u2192 raw object exists?</li> <li>EventsTable \u2192 metadata row exists?</li> <li>Status field (<code>ACCEPTED</code> vs <code>DUPLICATE</code>)</li> </ol> <p>If raw exists, ingest is working.</p>"},{"location":"guide/troubleshooting/#replay-issues","title":"Replay Issues","text":""},{"location":"guide/troubleshooting/#replay-returns-sent-0","title":"\u2757 Replay returns <code>sent = 0</code>","text":"<p>This is the most common confusion point.</p> <p>Possible reasons:</p> <ul> <li>no events in time window</li> <li>all events filtered out</li> <li><code>include_duplicates=false</code></li> <li>missing <code>s3_bucket</code> or <code>s3_key</code></li> </ul> <p>What to do:</p> <pre><code>aws dynamodb scan --table-name EVENTS_TABLE\n</code></pre> <p>Inspect rows manually.</p>"},{"location":"guide/troubleshooting/#replay-scans-items-but-sends-nothing","title":"\u2757 Replay scans items but sends nothing","text":"<p>Check:</p> <ul> <li><code>status</code> field</li> <li>missing S3 references</li> <li>limit reached early</li> </ul> <p>Replay is conservative by design.</p>"},{"location":"guide/troubleshooting/#processor-issues","title":"Processor Issues","text":""},{"location":"guide/troubleshooting/#processor-not-consuming-messages","title":"\u2757 Processor not consuming messages","text":"<p>Checklist:</p> <ul> <li>Is <code>EnableProcessor=true</code>?</li> <li>Does event source mapping exist?</li> <li>Is SQS empty?</li> </ul> <pre><code>aws lambda list-event-source-mappings\n</code></pre>"},{"location":"guide/troubleshooting/#processor-runs-but-aggregates-are-wrong","title":"\u2757 Processor runs but aggregates are wrong","text":"<p>This is expected during investigation.</p> <p>Check:</p> <ul> <li>multiple aggregate versions</li> <li>input hashes</li> <li>sample event IDs</li> </ul> <p>Aggregates are diagnostic outputs, not truth.</p>"},{"location":"guide/troubleshooting/#processor-errors-but-queue-drains","title":"\u2757 Processor errors but queue drains","text":"<p>This is dangerous.</p> <p>Fix immediately:</p> <pre><code>sam deploy --parameter-overrides EnableProcessor=false\n</code></pre> <p>This stops consumption without losing messages.</p>"},{"location":"guide/troubleshooting/#sqs-issues","title":"SQS Issues","text":""},{"location":"guide/troubleshooting/#messages-disappear","title":"\u2757 Messages disappear","text":"<p>Possible causes:</p> <ul> <li>processor enabled</li> <li>visibility timeout expired</li> <li>DLQ not configured (by design)</li> </ul> <p>Always inspect before enabling processor.</p>"},{"location":"guide/troubleshooting/#sqs-stays-empty-after-replay","title":"\u2757 SQS stays empty after replay","text":"<p>Check:</p> <ul> <li>replay logs</li> <li><code>sent</code> count</li> <li>IAM permissions (<code>sqs:SendMessage</code>)</li> </ul>"},{"location":"guide/troubleshooting/#dynamodb-issues","title":"DynamoDB Issues","text":""},{"location":"guide/troubleshooting/#scan-works-but-query-doesnt","title":"\u2757 Scan works but query doesn\u2019t","text":"<p>Likely:</p> <ul> <li>wrong index</li> <li>wrong key condition</li> <li>wrong partition key</li> </ul> <p>Remember:</p> <ul> <li><code>PK = ENTITY#&lt;id&gt;</code></li> <li><code>SK = TS#&lt;timestamp&gt;#EID#&lt;id&gt;</code></li> </ul>"},{"location":"guide/troubleshooting/#unexpected-aggregate-overwrites","title":"\u2757 Unexpected aggregate overwrites","text":"<p>Aggregates are append-only by design.</p> <p>If you see overwrites:</p> <ul> <li>check table schema</li> <li>check sort key versioning</li> <li>verify code changes</li> </ul>"},{"location":"guide/troubleshooting/#logging-metrics-issues","title":"Logging &amp; Metrics Issues","text":""},{"location":"guide/troubleshooting/#no-logs-in-cloudwatch","title":"\u2757 No logs in CloudWatch","text":"<p>Check:</p> <ul> <li>correct log group name</li> <li>correct region</li> <li>IAM role includes <code>AWSLambdaBasicExecutionRole</code></li> </ul>"},{"location":"guide/troubleshooting/#metrics-missing","title":"\u2757 Metrics missing","text":"<p>Ensure:</p> <ul> <li>EMF logs emitted</li> <li>namespace <code>PipelineInvestigationKit</code></li> <li>correct dimensions</li> </ul> <p>Metrics are written via logs.</p>"},{"location":"guide/troubleshooting/#local-vs-cloud-confusion","title":"Local vs Cloud Confusion","text":""},{"location":"guide/troubleshooting/#works-locally-but-not-in-aws","title":"\u2757 Works locally but not in AWS","text":"<p>Common causes:</p> <ul> <li>missing IAM permission</li> <li>missing env var</li> <li>wrong resource name</li> </ul> <p>Compare:</p> <pre><code>sam local invoke\naws lambda invoke\n</code></pre> <p>Side-by-side.</p>"},{"location":"guide/troubleshooting/#golden-debugging-path","title":"Golden Debugging Path","text":"<p>When confused, always do this in order:</p> <ol> <li>Inspect raw S3 data</li> <li>Inspect EventsTable rows</li> <li>Replay with DRY_RUN</li> <li>Inspect SQS messages</li> <li>Enable processor briefly</li> <li>Inspect aggregates</li> </ol> <p>Never skip steps.</p>"},{"location":"guide/troubleshooting/#what-not-to-do","title":"What NOT to Do","text":"<p>\u274c Delete raw data \u274c Rewrite aggregates \u274c Disable dedupe \u274c Replay without scoping \u274c Enable processor blindly</p>"},{"location":"guide/troubleshooting/#when-to-escalate","title":"When to Escalate","text":"<p>Escalate if:</p> <ul> <li>raw data missing</li> <li>ingest fails consistently</li> <li>IAM denies expected access</li> </ul> <p>Otherwise, the system is likely behaving correctly.</p>"},{"location":"guide/troubleshooting/#developer-guide-complete","title":"Developer Guide Complete \u2705","text":"<p>You now have:</p> <ul> <li>Architecture</li> <li>Quickstart</li> <li>Deployment</li> <li>Configuration</li> <li>Usage</li> <li>Troubleshooting</li> </ul> <p>This is a complete, production-grade investigation toolkit.</p>"},{"location":"guide/usage/","title":"Developer Guide \u2013 Usage","text":"<p>This section explains how the system is meant to be used day-to-day, especially during data pipeline incidents.</p> <p>This is not a \u201chappy path\u201d guide. It is an investigation-first workflow.</p>"},{"location":"guide/usage/#core-usage-philosophy","title":"Core Usage Philosophy","text":"<p>The Pipeline Investigation Kit is designed to answer questions like:</p> <ul> <li>Where did data break?</li> <li>When did it arrive late?</li> <li>Why did aggregates change?</li> <li>Can we replay safely?</li> </ul> <p>It is not a production pipeline. It is a truth-preserving diagnostic layer.</p>"},{"location":"guide/usage/#normal-flow-high-level","title":"Normal Flow (High Level)","text":"<ol> <li>Ingest receives events</li> <li>Raw data is stored immutably in S3</li> <li>Metadata is indexed in DynamoDB</li> <li>Replay selectively re-emits events</li> <li>Processor computes aggregates (optional)</li> </ol> <p>Each step is independently observable.</p>"},{"location":"guide/usage/#ingest-usage","title":"Ingest Usage","text":""},{"location":"guide/usage/#when-to-use-ingest","title":"When to Use Ingest","text":"<ul> <li>collecting raw events</li> <li>capturing late/out-of-order data</li> <li>recording \u201cbad\u201d events instead of dropping them</li> </ul>"},{"location":"guide/usage/#example-ingest-call","title":"Example Ingest Call","text":"<pre><code>curl -X POST \"$API_URL/ingest\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\":\"demo\",\n    \"event_type\":\"heartbeat\",\n    \"entity_id\":\"user_123\",\n    \"event_time\":\"2025-12-28T23:59:59Z\",\n    \"payload\":{\"steps\":10}\n  }'\n</code></pre>"},{"location":"guide/usage/#typical-responses","title":"Typical Responses","text":"Status Meaning <code>ACCEPTED</code> First time event seen <code>DUPLICATE</code> Idempotent replay <code>REJECTED</code> Invalid payload <p>Duplicates are expected and useful.</p>"},{"location":"guide/usage/#replay-usage","title":"Replay Usage","text":"<p>Replay is the heart of investigations.</p>"},{"location":"guide/usage/#when-to-replay","title":"When to Replay","text":"<ul> <li>missing aggregates</li> <li>incorrect dashboards</li> <li>delayed syncs</li> <li>backfills</li> </ul> <p>Replay never mutates data directly.</p>"},{"location":"guide/usage/#replay-example","title":"Replay Example","text":"<pre><code>curl -X POST \"$API_URL/replay\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"entity_id\":\"user_123\",\n    \"start_time\":\"2025-12-28T00:00:00Z\",\n    \"end_time\":\"2025-12-29T00:00:00Z\",\n    \"limit\":50,\n    \"include_duplicates\":false\n  }'\n</code></pre>"},{"location":"guide/usage/#replay-output","title":"Replay Output","text":"<pre><code>{\n  \"entity_id\": \"user_123\",\n  \"scanned\": 1,\n  \"sent\": 1\n}\n</code></pre> <ul> <li><code>scanned</code> = DynamoDB items scanned</li> <li><code>sent</code> = SQS messages emitted</li> </ul> <p>If <code>sent = 0</code>, that\u2019s a signal, not an error.</p>"},{"location":"guide/usage/#processor-usage","title":"Processor Usage","text":"<p>Processor is optional and dangerous by design.</p>"},{"location":"guide/usage/#when-to-enable-processor","title":"When to Enable Processor","text":"<p>Only after:</p> <ul> <li>ingest validated</li> <li>replay verified</li> <li>messages inspected</li> </ul> <p>Processor consumes from SQS automatically.</p>"},{"location":"guide/usage/#processor-output","title":"Processor Output","text":"<p>Processor writes:</p> <ul> <li>versioned aggregates</li> <li>input hashes</li> <li>sample event IDs</li> </ul> <p>This allows full auditability.</p>"},{"location":"guide/usage/#aggregate-inspection","title":"Aggregate Inspection","text":"<p>Query aggregates directly:</p> <pre><code>aws dynamodb scan \\\n  --table-name \"$AGG_TABLE\"\n</code></pre> <p>Look for:</p> <ul> <li>multiple versions per day</li> <li>changed input hashes</li> <li>unexpected recomputations</li> </ul> <p>Aggregate churn is a symptom, not a bug.</p>"},{"location":"guide/usage/#typical-investigation-playbooks","title":"Typical Investigation Playbooks","text":""},{"location":"guide/usage/#missing-day","title":"\ud83d\udd0d Missing Day","text":"<ol> <li>Replay for that day</li> <li>Inspect <code>sent</code> count</li> <li>Enable processor</li> <li>Compare aggregate versions</li> </ol>"},{"location":"guide/usage/#late-data","title":"\ud83d\udc22 Late Data","text":"<ol> <li>Check ingest lag metrics</li> <li>Query metadata by lag index</li> <li>Replay late window</li> <li>Observe aggregate change</li> </ol>"},{"location":"guide/usage/#duplicate-storm","title":"\ud83d\udd01 Duplicate Storm","text":"<ol> <li>Ingest duplicates safely</li> <li>Replay with <code>include_duplicates=false</code></li> <li>Confirm dedupe behavior</li> <li>Validate downstream idempotency</li> </ol>"},{"location":"guide/usage/#dry_run-workflow-strongly-recommended","title":"DRY_RUN Workflow (Strongly Recommended)","text":"<p>Before any real replay:</p> <pre><code>DRY_RUN=true\n</code></pre> <p>This lets you:</p> <ul> <li>measure blast radius</li> <li>estimate replay size</li> <li>validate filters</li> </ul> <p>Only disable DRY_RUN when confident.</p>"},{"location":"guide/usage/#usage-anti-patterns","title":"Usage Anti-Patterns","text":""},{"location":"guide/usage/#treating-replay-as-fix-button","title":"\u274c Treating Replay as \u201cFix Button\u201d","text":"<p>Replay is not magic. Bad inputs produce bad outputs.</p>"},{"location":"guide/usage/#blindly-enabling-processor","title":"\u274c Blindly Enabling Processor","text":"<p>Processor should be:</p> <ul> <li>intentional</li> <li>temporary</li> <li>observable</li> </ul>"},{"location":"guide/usage/#deleting-raw-data","title":"\u274c Deleting Raw Data","text":"<p>Raw data is your ground truth. Never delete it during an investigation.</p>"},{"location":"guide/usage/#usage-checklist","title":"Usage Checklist","text":"<p>Before closing an incident:</p> <ul> <li>[ ] Raw events verified</li> <li>[ ] Replay scoped correctly</li> <li>[ ] Processor behavior observed</li> <li>[ ] Aggregate version validated</li> <li>[ ] Root cause documented</li> </ul>"},{"location":"guide/usage/#next-troubleshooting","title":"Next: Troubleshooting","text":"<p>Next we\u2019ll cover:</p> <ul> <li>common failure modes</li> <li>misleading symptoms</li> <li>how to debug safely</li> </ul> <p>\ud83d\udc49 Continue with Guide \u2192 Troubleshooting</p>"},{"location":"quickstart/ingest_example/","title":"Ingest Example","text":"<p>This sends a raw event into the system. The ingest Lambda will:</p> <ul> <li>validate schema</li> <li>compute stable <code>event_id</code></li> <li>write immutable raw JSON to S3</li> <li>write metadata/index row to DynamoDB</li> <li>emit ingest metrics (lag, accepted/duplicate)</li> </ul>"},{"location":"quickstart/ingest_example/#1-send-an-event","title":"1) Send an event","text":"<pre><code>curl -sS -X POST \"$API_URL/ingest\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\":\"demo\",\n    \"event_type\":\"heartbeat\",\n    \"entity_id\":\"user_123\",\n    \"event_time\":\"2025-12-28T23:59:59Z\",\n    \"payload\":{\"steps\":10}\n  }'\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"event_id\": \"...\",\n  \"status\": \"ACCEPTED\",\n  \"ingest_lag_ms\": 12345,\n  \"s3_key\": \"raw/source=.../event_id=....json\"\n}\n</code></pre>"},{"location":"quickstart/ingest_example/#2-send-the-same-event-again-dedupe","title":"2) Send the same event again (dedupe)","text":"<pre><code>curl -sS -X POST \"$API_URL/ingest\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\":\"demo\",\n    \"event_type\":\"heartbeat\",\n    \"entity_id\":\"user_123\",\n    \"event_time\":\"2025-12-28T23:59:59Z\",\n    \"payload\":{\"steps\":10}\n  }'\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"event_id\": \"...\",\n  \"status\": \"DUPLICATE\",\n  \"ingest_lag_ms\": 12345,\n  \"s3_key\": \"raw/source=.../event_id=....json\"\n}\n</code></pre>"},{"location":"quickstart/ingest_example/#notes","title":"Notes","text":"<ul> <li><code>event_id</code> is stable for identical logical events.</li> <li><code>status=DUPLICATE</code> means the event was already seen before.</li> <li>The raw event is stored immutably in S3 under a partition-friendly prefix.</li> </ul>"},{"location":"quickstart/processor_example/","title":"Processor Example (Optional)","text":"<p>The processor consumes replay messages from SQS, loads raw events from S3, and writes a placeholder aggregate row into DynamoDB for traceability.</p>"},{"location":"quickstart/processor_example/#enable-processor","title":"Enable processor","text":"<p>Deploy with:</p> <pre><code>sam deploy --parameter-overrides EnableProcessor=true\n</code></pre> <p>This will add:</p> <ul> <li>Aggregates DynamoDB table</li> <li>SQS \u2192 Processor Lambda event source mapping</li> <li>Processor Lambda + IAM role</li> </ul>"},{"location":"quickstart/processor_example/#trigger-a-run","title":"Trigger a run","text":"<ol> <li>Ingest an event (see ingest example)</li> <li>Replay it (see replay example)</li> <li>Processor should consume from SQS automatically</li> </ol> <p>Check SQS (should go back to 0):</p> <pre><code>aws sqs get-queue-attributes \\\n  --queue-url \"$REPLAY_QUEUE_URL\" \\\n  --attribute-names ApproximateNumberOfMessages ApproximateNumberOfMessagesNotVisible\n</code></pre>"},{"location":"quickstart/processor_example/#verify-aggregates-table-writes","title":"Verify aggregates table writes","text":"<p>List aggregates:</p> <pre><code>aws dynamodb scan \\\n  --table-name \"&lt;YOUR_AGG_TABLE_NAME&gt;\" \\\n  --max-items 20\n</code></pre> <p>You should see fields like:</p> <ul> <li><code>metric_name</code> (e.g., <code>daily_event_count</code>)</li> <li><code>value</code></li> <li><code>inputs_hash</code></li> <li><code>sample_event_ids</code></li> <li><code>computed_at</code></li> </ul>"},{"location":"quickstart/processor_example/#why-this-is-useful","title":"Why this is useful","text":"<p>It proves an investigation loop:</p> <p>raw events \u2192 replay \u2192 processor \u2192 changing aggregate history.</p>"},{"location":"quickstart/quickstart/","title":"Quickstart","text":"<p>Get the investigation kit running and validate the core flows:</p> <p>1) Ingest events via HTTP 2) Confirm dedupe behavior 3) Replay events into SQS 4) (Optional) Enable processor to compute aggregates</p> <p>This repo is an investigation + observability toolkit, not a full production pipeline.</p>"},{"location":"quickstart/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS account + credentials configured (<code>aws configure</code>)</li> <li>AWS SAM CLI installed</li> <li>Docker running (for <code>sam local</code>)</li> <li>Python 3.11+</li> </ul>"},{"location":"quickstart/quickstart/#deploy-dev","title":"Deploy (dev)","text":"<p>From repo root:</p> <pre><code>sam build\nsam deploy --guided\n</code></pre> <p>During <code>--guided</code>:</p> <ul> <li>EnableProcessor: set <code>false</code> first (you can enable later)</li> <li>Authentication: for initial testing you can choose <code>N</code> (public). For real use, secure it.</li> </ul> <p>After deploy, you will get outputs like:</p> <ul> <li><code>ApiUrl</code></li> <li><code>RawBucketName</code></li> <li><code>EventsTableName</code></li> <li><code>DedupeTableName</code></li> <li><code>ReplayQueueUrl</code></li> </ul> <p>Export them locally (replace values):</p> <pre><code>export API_URL=\"https://xxxxx.execute-api.us-east-1.amazonaws.com/Prod\"\nexport REPLAY_QUEUE_URL=\"https://sqs.us-east-1.amazonaws.com/xxx/queue\"\n</code></pre> <p>Next: follow the examples:</p> <ul> <li>Ingest example</li> <li>Replay example</li> <li>Processor example (optional)</li> </ul>"},{"location":"quickstart/replay_example/","title":"Replay Example","text":"<p>Replay queries events by <code>entity_id</code> + time window and pushes them to SQS.</p>"},{"location":"quickstart/replay_example/#1-replay-for-an-entity-window","title":"1) Replay for an entity + window","text":"<pre><code>curl -sS -X POST \"$API_URL/replay\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"entity_id\":\"user_123\",\n    \"start_time\":\"2025-12-28T00:00:00Z\",\n    \"end_time\":\"2025-12-29T00:00:00Z\",\n    \"limit\":50,\n    \"include_duplicates\":false\n  }'\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"entity_id\":\"user_123\",\n  \"start_time\":\"...\",\n  \"end_time\":\"...\",\n  \"scanned\": 1,\n  \"sent\": 1\n}\n</code></pre>"},{"location":"quickstart/replay_example/#2-confirm-messages-are-in-sqs","title":"2) Confirm messages are in SQS","text":"<pre><code>aws sqs get-queue-attributes \\\n  --queue-url \"$REPLAY_QUEUE_URL\" \\\n  --attribute-names ApproximateNumberOfMessages ApproximateNumberOfMessagesNotVisible\n</code></pre> <p>Example:</p> <pre><code>{\n  \"Attributes\": {\n    \"ApproximateNumberOfMessages\": \"1\",\n    \"ApproximateNumberOfMessagesNotVisible\": \"0\"\n  }\n}\n</code></pre>"},{"location":"quickstart/replay_example/#message-format","title":"Message format","text":"<p>Each SQS message points to the raw event in S3:</p> <pre><code>{\n  \"event_id\": \"...\",\n  \"entity_id\": \"...\",\n  \"event_time\": \"2025-12-28T23:59:59Z\",\n  \"s3_bucket\": \"...\",\n  \"s3_key\": \"raw/source=.../event_id=....json\"\n}\n</code></pre>"},{"location":"quickstart/api-reference/ingest/","title":"Ingest API","text":"<p>The Ingest API is the entry point of the Pipeline Investigation Kit.</p> <p>Its responsibility is intentionally narrow:</p> <ul> <li>accept events</li> <li>deduplicate them safely</li> <li>store raw data immutably</li> <li>record metadata for investigation</li> </ul> <p>It does not transform, enrich, or aggregate data.</p>"},{"location":"quickstart/api-reference/ingest/#endpoint","title":"Endpoint","text":"<pre><code>POST /ingest\n</code></pre>"},{"location":"quickstart/api-reference/ingest/#request-payload","title":"Request Payload","text":"<pre><code>{\n  \"source\": \"demo\",\n  \"event_type\": \"heartbeat\",\n  \"entity_id\": \"user_123\",\n  \"event_time\": \"2025-12-28T23:59:59Z\",\n  \"payload\": {\n    \"steps\": 10\n  }\n}\n</code></pre>"},{"location":"quickstart/api-reference/ingest/#required-fields","title":"Required Fields","text":"Field Description <code>source</code> Origin system (service, app, vendor) <code>event_type</code> Logical event type <code>entity_id</code> Entity identifier (user, device, account, etc.) <code>event_time</code> When the event actually occurred (ISO-8601) <code>payload</code> Arbitrary JSON payload <p>All fields are required.</p>"},{"location":"quickstart/api-reference/ingest/#event-id-strategy","title":"Event ID Strategy","text":"<p>A stable <code>event_id</code> is generated server-side using a deterministic hash:</p> <pre><code>hash(source + event_type + entity_id + event_time + payload)\n</code></pre> <p>This guarantees:</p> <ul> <li>idempotent ingestion</li> <li>safe client retries</li> <li>deterministic deduplication</li> <li>reproducible replay</li> </ul> <p>Clients do not send <code>event_id</code>.</p>"},{"location":"quickstart/api-reference/ingest/#deduplication-behavior","title":"Deduplication Behavior","text":"<p>Deduplication is based on <code>event_id</code>.</p> <ul> <li>First occurrence \u2192 <code>ACCEPTED</code></li> <li>Subsequent occurrences \u2192 <code>DUPLICATE</code></li> </ul> <p>Duplicates are:</p> <ul> <li>expected</li> <li>recorded</li> <li>observable</li> </ul> <p>They are not errors.</p>"},{"location":"quickstart/api-reference/ingest/#storage-model","title":"Storage Model","text":""},{"location":"quickstart/api-reference/ingest/#raw-events-s3","title":"Raw Events (S3)","text":"<ul> <li>Stored as immutable JSON objects</li> <li>Never overwritten or deleted by the system</li> <li> <p>Partitioned by:</p> </li> <li> <p>source</p> </li> <li>event_type</li> <li>event_date</li> <li>ingest_date</li> <li>hour</li> </ul> <p>Example key:</p> <pre><code>raw/source=demo/event_type=heartbeat/event_date=2025-12-28/ingest_date=2025-12-29/hour=23/event_id=....json\n</code></pre>"},{"location":"quickstart/api-reference/ingest/#metadata-dynamodb","title":"Metadata (DynamoDB)","text":"<p>Each ingest writes a metadata record containing:</p> <ul> <li>event identifiers</li> <li>entity and time info</li> <li>ingest timestamp</li> <li>ingest lag</li> <li>status (<code>ACCEPTED</code> / <code>DUPLICATE</code>)</li> <li>S3 location</li> <li>payload hash</li> </ul> <p>This table is optimized for investigation queries.</p>"},{"location":"quickstart/api-reference/ingest/#ingest-lag","title":"Ingest Lag","text":"<p>The system computes:</p> <pre><code>ingest_lag_ms = ingest_time - event_time\n</code></pre> <p>This allows detection of:</p> <ul> <li>late arrivals</li> <li>backfills</li> <li>delayed syncs</li> </ul> <p>Lag is indexed and queryable.</p>"},{"location":"quickstart/api-reference/ingest/#responses","title":"Responses","text":""},{"location":"quickstart/api-reference/ingest/#accepted-event","title":"Accepted Event","text":"<pre><code>{\n  \"event_id\": \"...\",\n  \"status\": \"ACCEPTED\",\n  \"ingest_lag_ms\": 72936580,\n  \"s3_key\": \"raw/...\"\n}\n</code></pre>"},{"location":"quickstart/api-reference/ingest/#duplicate-event","title":"Duplicate Event","text":"<pre><code>{\n  \"event_id\": \"...\",\n  \"status\": \"DUPLICATE\",\n  \"ingest_lag_ms\": 72956085,\n  \"s3_key\": \"raw/...\"\n}\n</code></pre> <p>The same <code>event_id</code> is returned for duplicates.</p>"},{"location":"quickstart/api-reference/ingest/#dry_run-mode","title":"DRY_RUN Mode","text":"<p>When <code>DRY_RUN=true</code>:</p> <ul> <li>payload is validated</li> <li><code>event_id</code> is generated</li> <li>no S3 writes</li> <li>no DynamoDB writes</li> <li>metrics are still emitted</li> </ul> <p>This enables safe testing in production.</p>"},{"location":"quickstart/api-reference/ingest/#observability","title":"Observability","text":""},{"location":"quickstart/api-reference/ingest/#metrics","title":"Metrics","text":"<ul> <li><code>IngestRequestCount</code></li> <li><code>DuplicateCount</code></li> <li><code>IngestLagMs</code></li> </ul>"},{"location":"quickstart/api-reference/ingest/#logs","title":"Logs","text":"<ul> <li>structured JSON</li> <li>include event_id and entity_id</li> <li>safe for correlation</li> </ul>"},{"location":"quickstart/api-reference/ingest/#failure-handling","title":"Failure Handling","text":"<ul> <li>Invalid payload \u2192 rejected</li> <li>Missing fields \u2192 rejected</li> <li>Internal errors \u2192 surfaced</li> </ul> <p>No data is silently dropped.</p>"},{"location":"quickstart/api-reference/ingest/#design-guarantees","title":"Design Guarantees","text":"<ul> <li>Raw data is immutable</li> <li>Deduplication is deterministic</li> <li>Ingest is idempotent</li> <li>No side effects beyond storage</li> </ul>"},{"location":"quickstart/api-reference/ingest/#when-to-use-ingest","title":"When to Use Ingest","text":"<ul> <li>capturing raw events</li> <li>recording late or out-of-order data</li> <li>preserving investigation context</li> <li>debugging upstream failures</li> </ul> <p>If you are unsure whether to ingest something: ingest it.</p>"},{"location":"quickstart/api-reference/processor/","title":"Processor Service","text":"<p>The Processor service consumes replayed events and produces derived aggregates.</p> <p>It is the execution layer of the Pipeline Investigation Kit.</p> <p>Processor answers the question:</p> <p>\u201cGiven these events, what metrics should exist?\u201d</p>"},{"location":"quickstart/api-reference/processor/#role-in-the-pipeline","title":"Role in the Pipeline","text":"<pre><code>Replay API \u2192 SQS \u2192 Processor \u2192 AggregatesTable\n</code></pre> <p>Processor never talks to the API directly. It only reacts to messages already validated and scoped by Replay.</p>"},{"location":"quickstart/api-reference/processor/#input-source","title":"Input Source","text":"<p>Processor is triggered by an SQS queue populated by the Replay service.</p> <p>Each message represents a single immutable event reference:</p> <pre><code>{\n  \"event_id\": \"e123\",\n  \"entity_id\": \"user_123\",\n  \"event_time\": \"2025-12-28T23:59:59Z\",\n  \"s3_bucket\": \"pipeline-raw-bucket\",\n  \"s3_key\": \"raw/source=demo/...\"\n}\n</code></pre>"},{"location":"quickstart/api-reference/processor/#processing-flow","title":"Processing Flow","text":"<p>For each message:</p> <ol> <li>Load raw event from S3</li> <li>Validate payload structure</li> <li>Apply aggregation logic</li> <li>Write aggregate results to DynamoDB</li> <li>Emit metrics</li> </ol> <p>Failures are isolated per message.</p>"},{"location":"quickstart/api-reference/processor/#aggregation-model","title":"Aggregation Model","text":"<p>Processor writes results into AggregatesTable.</p> <p>Each aggregate represents a windowed metric.</p> <p>Example:</p> <pre><code>{\n  \"PK\": \"ENTITY#user_123\",\n  \"SK\": \"DAY#2025-12-28#VER#1767043865\",\n  \"metric_name\": \"daily_event_count\",\n  \"value\": 1,\n  \"window_start\": \"2025-12-28T00:00:00Z\",\n  \"window_end\": \"2025-12-28T23:59:59Z\"\n}\n</code></pre>"},{"location":"quickstart/api-reference/processor/#idempotency","title":"Idempotency","text":"<p>Processor is idempotent by design.</p> <ul> <li>Aggregates are keyed by deterministic window identifiers</li> <li>Reprocessing the same event produces the same result</li> <li>Replay can safely be executed multiple times</li> </ul>"},{"location":"quickstart/api-reference/processor/#dry_run-mode","title":"DRY_RUN Mode","text":"<p>When <code>DRY_RUN=true</code>:</p> <ul> <li>messages are read</li> <li>events are parsed</li> <li>metrics are computed</li> <li>no DynamoDB writes occur</li> </ul> <p>Processor returns counts only.</p> <p>This allows safe testing of aggregation logic.</p>"},{"location":"quickstart/api-reference/processor/#metrics","title":"Metrics","text":"<p>Processor emits the following CloudWatch metrics:</p> <ul> <li><code>ProcessorMessageCount</code></li> <li><code>ProcessorErrorCount</code></li> </ul> <p>These metrics are critical for validating replay outcomes.</p>"},{"location":"quickstart/api-reference/processor/#error-handling","title":"Error Handling","text":"<ul> <li>malformed events are skipped</li> <li>missing S3 objects are logged</li> <li>aggregation failures increment error metrics</li> <li>the Lambda does not crash the batch</li> </ul> <p>This ensures partial failures do not block investigations.</p>"},{"location":"quickstart/api-reference/processor/#scaling-characteristics","title":"Scaling Characteristics","text":"<ul> <li>SQS controls concurrency</li> <li>Processor scales horizontally</li> <li>Backpressure is automatic</li> </ul> <p>Replay volume directly controls processing pressure.</p>"},{"location":"quickstart/api-reference/processor/#what-processor-is-not","title":"What Processor Is NOT","text":"<ul> <li>Not a stream processor</li> <li>Not real-time analytics</li> <li>Not a scheduler</li> </ul> <p>Processor is intentionally reactive and scoped.</p>"},{"location":"quickstart/api-reference/processor/#design-philosophy","title":"Design Philosophy","text":"<p>Processor favors:</p> <ul> <li>determinism over speed</li> <li>observability over automation</li> <li>correctness over convenience</li> </ul> <p>If results surprise you, the system is doing its job.</p>"},{"location":"quickstart/api-reference/processor/#typical-workflow","title":"Typical Workflow","text":"<ol> <li>Ingest raw events</li> <li>Replay a scoped window</li> <li>Observe processor metrics</li> <li>Inspect aggregates</li> <li>Iterate safely</li> </ol> <p>Processor is an optional but powerful extension to the Pipeline Investigation Kit.</p>"},{"location":"quickstart/api-reference/replay/","title":"Replay Service","text":"<p>The Replay service enables controlled re-emission of previously ingested events.</p> <p>It is the core investigation tool of the Pipeline Investigation Kit.</p> <p>Replay answers the question:</p> <p>\u201cWhat would happen if these exact events were processed again?\u201d</p>"},{"location":"quickstart/api-reference/replay/#endpoint","title":"Endpoint","text":"<pre><code>POST /replay\n</code></pre>"},{"location":"quickstart/api-reference/replay/#request-payload","title":"Request Payload","text":"<pre><code>{\n  \"entity_id\": \"user_123\",\n  \"start_time\": \"2025-12-28T00:00:00Z\",\n  \"end_time\": \"2025-12-29T00:00:00Z\",\n  \"limit\": 50,\n  \"include_duplicates\": false\n}\n</code></pre>"},{"location":"quickstart/api-reference/replay/#parameters","title":"Parameters","text":"Field Description <code>entity_id</code> Entity whose events will be replayed <code>start_time</code> Start of replay window (ISO-8601) <code>end_time</code> End of replay window (ISO-8601) <code>limit</code> Maximum number of events to replay <code>include_duplicates</code> Whether to include duplicate events <p>All parameters are required except <code>limit</code> (defaults to 500).</p>"},{"location":"quickstart/api-reference/replay/#what-replay-does","title":"What Replay Does","text":"<p>Replay performs read-only investigation followed by optional re-emission.</p> <p>Step by step:</p> <ol> <li>Query <code>EventsTable</code> by <code>entity_id</code></li> <li>Filter events by time window</li> <li>Apply deduplication rules</li> <li>Build replay messages</li> <li>Send messages to SQS</li> <li>Emit metrics</li> </ol> <p>Replay never modifies stored data.</p>"},{"location":"quickstart/api-reference/replay/#replay-filtering-rules","title":"Replay Filtering Rules","text":"<p>Replay messages are built using the following rules:</p> <ul> <li>events without <code>event_id</code> are skipped</li> <li>events without <code>s3_bucket</code> or <code>s3_key</code> are skipped</li> <li>when <code>include_duplicates=false</code>, each <code>event_id</code> is emitted only once</li> <li>events are emitted in query order</li> <li>replay stops when <code>limit</code> is reached</li> </ul> <p>These rules are conservative by design.</p>"},{"location":"quickstart/api-reference/replay/#replay-output","title":"Replay Output","text":"<pre><code>{\n  \"entity_id\": \"user_123\",\n  \"start_time\": \"2025-12-28T00:00:00Z\",\n  \"end_time\": \"2025-12-29T00:00:00Z\",\n  \"scanned\": 12,\n  \"sent\": 7\n}\n</code></pre>"},{"location":"quickstart/api-reference/replay/#fields","title":"Fields","text":"Field Meaning <code>scanned</code> Number of DynamoDB items read <code>sent</code> Number of SQS messages emitted <p>A response with <code>sent = 0</code> is valid and meaningful.</p>"},{"location":"quickstart/api-reference/replay/#dry_run-mode","title":"DRY_RUN Mode","text":"<p>When <code>DRY_RUN=true</code>:</p> <ul> <li>DynamoDB is queried</li> <li>filtering rules are applied</li> <li>no SQS messages are sent</li> <li>metrics are still emitted</li> </ul> <p>This allows safe estimation of replay impact.</p>"},{"location":"quickstart/api-reference/replay/#observability","title":"Observability","text":""},{"location":"quickstart/api-reference/replay/#metrics","title":"Metrics","text":"<ul> <li><code>ReplayRequestedCount</code></li> <li><code>ReplayMessageCount</code></li> </ul>"},{"location":"quickstart/api-reference/replay/#logs","title":"Logs","text":"<p>Replay logs include:</p> <ul> <li>query parameters</li> <li>filtering decisions</li> <li>final counts</li> </ul> <p>All logs are structured JSON.</p>"},{"location":"quickstart/api-reference/replay/#common-use-cases","title":"Common Use Cases","text":""},{"location":"quickstart/api-reference/replay/#missing-aggregates","title":"Missing Aggregates","text":"<p>Replay a specific day or entity to verify:</p> <ul> <li>whether events exist</li> <li>how many would be processed</li> </ul>"},{"location":"quickstart/api-reference/replay/#late-data","title":"Late Data","text":"<p>Replay a delayed window to:</p> <ul> <li>surface late arrivals</li> <li>observe aggregate changes</li> </ul>"},{"location":"quickstart/api-reference/replay/#duplicate-storms","title":"Duplicate Storms","text":"<p>Replay with <code>include_duplicates=false</code> to:</p> <ul> <li>verify deduplication</li> <li>limit downstream impact</li> </ul>"},{"location":"quickstart/api-reference/replay/#safety-guarantees","title":"Safety Guarantees","text":"<ul> <li>Replay is explicit</li> <li>Replay is scoped</li> <li>Replay is reversible</li> <li>Replay is observable</li> </ul> <p>Nothing happens automatically.</p>"},{"location":"quickstart/api-reference/replay/#what-replay-is-not","title":"What Replay Is NOT","text":"<ul> <li>Not a backfill engine</li> <li>Not a migration tool</li> <li>Not a repair mechanism by itself</li> </ul> <p>Replay provides visibility, not magic.</p>"},{"location":"quickstart/api-reference/replay/#design-philosophy","title":"Design Philosophy","text":"<p>Replay is intentionally:</p> <ul> <li>conservative</li> <li>predictable</li> <li>debuggable</li> </ul> <p>If replay feels \u201cslow\u201d or \u201cmanual\u201d, that is by design.</p>"}]}